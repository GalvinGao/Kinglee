{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Title</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import math\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Classifies the test data and generates the submissions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"__author__ = 'Marin Iuga'\n",
    "__copyright__ = 'Copyright 2018, Marin Iuga / Intertechnica Business Solutions SRL'\n",
    "__credits__ = ['Marin Iuga']\n",
    "__license__ = 'MIT'\n",
    "__version__ = '1.0'\n",
    "__maintainer__ = 'Marin Iuga'\n",
    "__email__ = 'marin.iuga@intertechnica.com'\n",
    "__status__ = 'Production'\n",
    "\"\"\"\n",
    "\n",
    "#configuration data \n",
    "image_height = 128//1\n",
    "image_width = 2*118//1\n",
    "training_image_count = 988\n",
    "testing_image_count = 659\n",
    "classes_count = 11\n",
    "\n",
    "data_root_path = '/mnt/c/user/我的电脑/desktop/data-release/'\n",
    "\n",
    "training_image_data_file_path = data_root_path + 'image_train.data'\n",
    "training_labels_data_file_path = data_root_path + 'image_train_labels.csv'\n",
    "testing_data_file_path = data_root_path + 'image_test.data'\n",
    "\n",
    "testing_submission_file_path = data_root_path + 'submission_format.csv'\n",
    "submission_results_file_path =  data_root_path + 'submission_results.csv'\n",
    "\n",
    "def read_image(p_image_data_file_path, p_position, p_image_width, p_image_height) :\n",
    "    \"\"\"\n",
    "    Reads an image from an image data from a image data repository @see prepare_data.py\n",
    "    @params:\n",
    "        p_image_data_file_path - Required : the image data file path (String)\n",
    "        p_position - Required : second image source (int)\n",
    "        p_image_width - Required: the image width (int)\n",
    "        p_image_height - Required: the image height (int)\n",
    "    \n",
    "    @returns:\n",
    "        The image data (array)    \n",
    "    \"\"\"  \n",
    "    with open(p_image_data_file_path, \"rb\") as image_file :\n",
    "        image_file.seek(p_position * p_image_height* p_image_width)\n",
    "        data = image_file.read(p_image_height * p_image_width)\n",
    "    \n",
    "        data_b = np.frombuffer(data, dtype=np.uint8)\n",
    "\n",
    "    return np.asarray(data_b)\n",
    "\n",
    "def process_images(p_images, p_image_width, p_image_height) :\n",
    "    \"\"\"\n",
    "    Processes a set of images so it can be classified by the neurals network model\n",
    "    @params:\n",
    "        p_images - Required : the images to process (String)\n",
    "        p_image_width - Required: the image width (int)\n",
    "        p_image_height - Required: the image height (int)\n",
    "    \"\"\"  \n",
    "    #reshape according to inputs accepted by a Conv2d layer\n",
    "    processed_images = p_images.reshape(p_images.shape[0], p_image_height, p_image_width, 1)\n",
    "\n",
    "    #data normalization to max value (0-255 grayscale values)\n",
    "    processed_images = (processed_images * 1.0) /255\n",
    " \n",
    "    return processed_images\n",
    "  \n",
    "def read_labels(p_labels_file_path) :\n",
    "    \"\"\"\n",
    "    Reads the extracted training labels @see prepare_data.py\n",
    "    @params:\n",
    "        p_labels_file_path - Required : the data file path (String)\n",
    "    @returns:\n",
    "        A dataframe containing the read labels with the column [id] for ordinal id and [label] for the label value    \n",
    "    \"\"\" \n",
    "    labels = pd.read_csv(p_labels_file_path, header= None)\n",
    "    labels.columns = [\"id\", \"label\"]\n",
    "  \n",
    "    return labels\n",
    "\n",
    "def process_labels(p_labels) :\n",
    "    \"\"\"\n",
    "    Processes the read labels\n",
    "    @params:\n",
    "        p_labels - Required: the read labels (array)\n",
    "    @returns:\n",
    "        The processed labels (binarization - one hot-encoded)    \n",
    "    \"\"\"\n",
    "    processed_labels = LabelBinarizer().fit_transform(p_labels)\n",
    "    \n",
    "    return processed_labels\n",
    "\n",
    "def generate_train_set(\n",
    "    p_image_training_data_file_path, \n",
    "    p_labels_file_path, \n",
    "    p_train_set_size, \n",
    "    p_image_width, \n",
    "    p_image_height\n",
    ") :\n",
    "    \"\"\"\n",
    "    Generates the training data set\n",
    "    @params:\n",
    "        p_image_training_data_file_path - Required: the training image data file path (String)\n",
    "        p_labels_file_path - Required: the labels file path (String)\n",
    "        p_train_set_size - Required: the size of the training set (int)\n",
    "        p_image_width - Required: the image width (int)\n",
    "        p_image_height - Required: the image height (int)\n",
    "    @returns:\n",
    "        (train_labels_processed, train_images_processed) tuple wiht the the processed train labels (array) \n",
    "        and the processed train images (array)\n",
    "    \"\"\"\n",
    "    labels = read_labels(p_labels_file_path)\n",
    "    \n",
    "    labels_batch = np.zeros(p_train_set_size)\n",
    "    labels_batch = labels[\"label\"][0:p_train_set_size].values\n",
    "\n",
    "    images_batch = []\n",
    "  \n",
    "    for i in range(0, p_train_set_size) :\n",
    "        image_data = read_image(p_image_training_data_file_path, i, p_image_width, p_image_height)\n",
    "        images_batch.append(image_data.reshape(p_image_height, p_image_width))\n",
    "  \n",
    "    train_labels_processed = process_labels(labels_batch)\n",
    "  \n",
    "    train_images_processed = process_images(np.array(images_batch), p_image_width, p_image_height)\n",
    "  \n",
    "    return train_labels_processed, train_images_processed\n",
    "\n",
    "def generate_test_set(\n",
    "    p_test_image_data_file_path, \n",
    "    p_test_set_size, \n",
    "    p_image_width, \n",
    "    p_image_height\n",
    ") :\n",
    "    \"\"\"\n",
    "    Generates the test data set\n",
    "    @params:\n",
    "        p_test_image_data_file_path - Required: the testing image data file path (String)\n",
    "        p_test_set_size - Required: the size of the testing set (int)\n",
    "        p_image_width - Required: the image width (int)\n",
    "        p_image_height - Required: the image height (int)\n",
    "    @returns:\n",
    "        test_images_processed the processed test images (array)\n",
    "    \"\"\"\n",
    "    images_batch = []\n",
    "\n",
    "    for i in range(0, p_test_set_size) :\n",
    "        image_data = read_image(p_test_image_data_file_path, i, p_image_width, p_image_height)\n",
    "        images_batch.append(image_data.reshape(p_image_height, p_image_width))\n",
    "\n",
    "    test_images_processed = process_images(np.array(images_batch), p_image_width, p_image_height)\n",
    "\n",
    "    return test_images_processed  \n",
    "  \n",
    "  \n",
    "def create_model(p_image_width, p_image_height, p_num_classes) :\n",
    "    \"\"\"\n",
    "    Creates the compiled model for image classification.\n",
    "    @params:\n",
    "        p_image_width - Required: the image width (int)\n",
    "        p_image_height - Required: the image height (int)\n",
    "        p_num_classes - Required: the number of classes\n",
    "    @returns:\n",
    "      The created and compiled model (Model)        \n",
    "    \"\"\"\n",
    "    input_shape = (p_image_height, p_image_width, 1)\n",
    "\n",
    "    #we will use a sequential model for training \n",
    "    model = Sequential()\n",
    "\t\n",
    "    #CONV 3x3x32 => RELU => NORMALIZATION => MAX POOL 3x3 block\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    #CONV 3x3x64 => RELU => NORMALIZATION => MAX POOL 2x2 block\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #CONV 3x3x128 => RELU => NORMALIZATION => MAX POOL 2x2 block\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #FLATTEN => DENSE 1024 => RELU => NORMALIZATION block\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #final DENSE => SOFTMAX block for multi-label classification\n",
    "    model.add(Dense(p_num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    #using categorical_crossentropy loss function with adam optimizer\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(\n",
    "    p_model, \n",
    "    p_training_image_data, \n",
    "    p_trainging_labels, \n",
    "    p_batch_size = 32, \n",
    "    p_epochs_to_train = 50, \n",
    "    p_verbose_level = 2\n",
    ") :\n",
    "    \"\"\"\n",
    "    Trains the model using the train image data and train labels.\n",
    "    \n",
    "    @parameters:\n",
    "      p_model - Required: the Keras model to be trained (Model)\n",
    "      p_training_image_data - Required: the image data used for training (array)\n",
    "      p_training_labels - Required: the training labels used fo training (array)\n",
    "      p_batch_size - Optional, default 32: the batch size used for training (int)\n",
    "      p_epochs_to_train - Optional, default 50: number of training epochs (int)\n",
    "      p_verbose_level - Optional, default 2: the Keras verbose level (int)\n",
    "    \n",
    "    @returns:\n",
    "      The trained model (Model)\n",
    "    \"\"\"    \n",
    "    p_model.fit(\n",
    "        x = p_training_image_data, \n",
    "        y = p_trainging_labels, \n",
    "        batch_size = p_batch_size, \n",
    "        epochs = p_epochs_to_train,\n",
    "        shuffle = True,\n",
    "        verbose = p_verbose_level    \n",
    "    )\n",
    "    \n",
    "    return p_model\n",
    "\n",
    "def predict_labels(p_model, p_test_image_data, p_batch_size = 32) :\n",
    "    \"\"\"\n",
    "    Predicts the labels associated with the test data.\n",
    "    \n",
    "    @parameters:\n",
    "      p_model - Required: the Keras model to be used (Model)\n",
    "      p_test_image_data - Required: the image data used for testing (array)\n",
    "      p_batch_size - Optional, default 32: the batch size used for training (int)\n",
    "    \n",
    "    @returns:\n",
    "      The predicted label (array)\n",
    "    \"\"\"      \n",
    "    labels = p_model.predict_classes(p_test_image_data, p_batch_size)\n",
    "  \n",
    "    return labels\n",
    "\n",
    "def write_results(\n",
    "    p_testing_submission_file_path, \n",
    "    p_submission_results_file_path, \n",
    "    p_results\n",
    ") :\n",
    "    \"\"\"\n",
    "    Writes the result to the output file.\n",
    "    \n",
    "    @parameters:\n",
    "      p_testing_submission_file_path - Required: the path to the submission format (String)\n",
    "      p_submission_results_file_path - Required: the path to the output file (String)\n",
    "      p_results - Required: the results to be written in the outut file (array)\n",
    "    \"\"\"     \n",
    "    submission_structure = pd.read_csv(p_testing_submission_file_path)\n",
    "    submission_structure['appliance'] = p_results\n",
    "    submission_structure.to_csv(p_submission_results_file_path, index=False)\n",
    "  \n",
    "# main\n",
    "def classify():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    #prepare training data\n",
    "    logging.info('Reading training data ...')\n",
    "    train_labels, train_images = generate_train_set(\n",
    "        training_image_data_file_path, \n",
    "        training_labels_data_file_path, \n",
    "        training_image_count, \n",
    "        image_width, \n",
    "        image_height\n",
    "    )\n",
    "    logging.info('Reading training data DONE')\n",
    "    \n",
    "    #create and train model\n",
    "    logging.info('Creating model ...')\n",
    "    model = create_model (image_width, image_height, classes_count)\n",
    "    logging.info('Creating model DONE')\n",
    "\n",
    "    logging.info('Training model ... ')\n",
    "    model = train_model(model, train_images, train_labels, p_epochs_to_train = 50)\n",
    "    logging.info('Training model DONE')\n",
    "    \n",
    "    #create test data\n",
    "    logging.info('Reading testing data ...')\n",
    "    test_images = generate_test_set(\n",
    "      testing_data_file_path, \n",
    "      testing_image_count, \n",
    "      image_width, \n",
    "      image_height\n",
    "    )\n",
    "    logging.info('Reading testing data DONE')\n",
    "    \n",
    "    #predict labels for test data\n",
    "    logging.info('Predicting test data classes ...')\n",
    "    result = predict_labels(model, test_images)\n",
    "    logging.info('Predicting test data classes DONE')\n",
    "    \n",
    "    #write results\n",
    "    logging.info('Writing results ...')\n",
    "    write_results(\n",
    "        testing_submission_file_path, \n",
    "        submission_results_file_path, \n",
    "        result\n",
    "    )\n",
    "    logging.info('Writing results DONE')\n",
    "    \n",
    "    \n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Prepares data for easier processing by the neural net classifier.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Marin Iuga'\n",
    "__copyright__ = 'Copyright 2018, Marin Iuga / Intertechnica Business Solutions SRL'\n",
    "__credits__ = ['Marin Iuga']\n",
    "__license__ = 'MIT'\n",
    "__version__ = '1.0'\n",
    "__maintainer__ = 'Marin Iuga'\n",
    "__email__ = 'marin.iuga@intertechnica.com'\n",
    "__status__ = 'Production'\n",
    "\n",
    "#Configuration/parameters\n",
    "classes_count = 11\n",
    "image_width = (2*118)//1\n",
    "image_height = 128//1\n",
    "image_data_size = image_width*image_height\n",
    "channels = 1\n",
    "\n",
    "data_root_path = '/mnt/c/users/我的电脑/desktop/data-release/'\n",
    "\n",
    "input_data_file_path = data_root_path + 'data-release.zip'\n",
    "\n",
    "training_image_data_file_path = data_root_path + 'image_train.data'\n",
    "training_labels_data_file_path = data_root_path + 'image_train_labels.csv'\n",
    "testing_data_file_path = data_root_path + 'image_test.data'\n",
    "\n",
    "testing_submission_file_path = data_root_path + 'submission_format.csv'\n",
    "\n",
    "def compose_train_image(p_img1, p_img2) :\n",
    "    \"\"\"\n",
    "    Creates a horizontally stacked image using two input images\n",
    "    @params:\n",
    "        p_img1 - Required : first image source (Image)\n",
    "        p_img2 - Required : second image source (Image) \n",
    "    @returns:\n",
    "        The stacked image (Image)    \n",
    "    \"\"\" \n",
    "\n",
    "    #Stacks images horizontally (i.e. one afer another on width axis)\n",
    "    img_merge_data = np.hstack([np.asarray(p_img1), np.asarray(p_img2)])\n",
    "    img_merge = Image.fromarray( img_merge_data )\n",
    "        \n",
    "    return img_merge\n",
    "\n",
    "def get_image_data(p_image) :\n",
    "    \"\"\"\n",
    "    Returns a flatten array of image pixel values (1 channel gray pallete)\n",
    "    @params:\n",
    "        p_image - Required : the input image (Image)\n",
    "    @returns:\n",
    "        Flattened array of image data (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    #Generates image data from the received image object\n",
    "    width, height = p_image.size\n",
    "    data = np.asarray(p_image).reshape(height*width)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_trainining_images_data_file(p_input_data_file_path, p_training_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates training information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_training_data_file_path - Required: the output training data file path (String)\n",
    "    @returns:\n",
    "        The extracted training labels (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    training_labels_file_path = 'train_labels.csv'\n",
    "    \n",
    "    labels = None\n",
    "\n",
    "    with open(p_training_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(training_labels_file_path) as train_labels_file:\n",
    "                content = train_labels_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    train_labels = pd.read_csv(io_content)\n",
    "\n",
    "                    max_count = train_labels.shape[0]    \n",
    "                    labels = np.zeros(max_count)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in train_labels.iterrows() :\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "\n",
    "                        labels[count] = row[\"appliance\"]\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return labels[:count]\n",
    "\n",
    "def create_training_labels(p_labels, p_labels_data_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the training labels to a destination file\n",
    "    @params:\n",
    "        p_labels - Required: the array of labels (array)\n",
    "    \"\"\" \n",
    "\n",
    "    classes = pd.DataFrame(p_labels.astype(int))\n",
    "    classes.to_csv(p_labels_data_file_path, header=None)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_testing_images_data_file(p_input_data_file_path, p_testing_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates testing information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_data_file_path - Required: the output testing data file path (String)\n",
    "    @returns:\n",
    "        The count of test images (int)\n",
    "    \"\"\"  \n",
    "\n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with open(p_testing_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "                content = submission_format_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    submission_indexes = pd.read_csv(io_content)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in submission_indexes.iterrows() :\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return count\n",
    "\n",
    "def create_testing_submission(p_input_data_file_path, p_testing_submission_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the submission data to a destination file\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_submission_file_path - Required: the testing submission file path (String)\n",
    "    \"\"\" \n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with ZipFile(p_input_data_file_path) as data_zip:\n",
    "        with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "            content = submission_format_file.read()\n",
    "            with BytesIO(content) as io_content:\n",
    "                submission_indexes = pd.read_csv(io_content)\n",
    "                submission_indexes.to_csv(p_testing_submission_file_path, index=False)\n",
    "\n",
    "    return\n",
    "\n",
    "# main\n",
    "def prepare() :\n",
    "    \"\"\"\n",
    "    Entry point\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    #create training data\n",
    "    logging.info('Creating training data ...')\n",
    "    training_labels  = create_trainining_images_data_file(input_data_file_path, training_image_data_file_path)\n",
    "    create_training_labels(training_labels, training_labels_data_file_path)\n",
    "    logging.info(\"Processed training images count: %d\" % training_labels.shape[0])\n",
    "    logging.info('Creating training data DONE')\n",
    "\n",
    "    logging.info('Creating testing data ...')\n",
    "    testing_count = create_testing_images_data_file(input_data_file_path, testing_data_file_path)\n",
    "    create_testing_submission(input_data_file_path, testing_submission_file_path)\n",
    "    logging.info(\"Processed testing images count: %d\" % testing_count)\n",
    "    logging.info('Creating testing data DONE')\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating training data ...\n",
      "INFO:root:Processed training images count: 988\n",
      "INFO:root:Creating training data DONE\n",
      "INFO:root:Creating testing data ...\n",
      "INFO:root:Processed testing images count: 659\n",
      "INFO:root:Creating testing data DONE\n"
     ]
    }
   ],
   "source": [
    "prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading training data ...\n",
      "INFO:root:Reading training data DONE\n",
      "INFO:root:Creating model ...\n",
      "INFO:root:Creating model DONE\n",
      "INFO:root:Training model ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 88s - loss: 1.4325 - accuracy: 0.6437\n",
      "Epoch 2/50\n",
      " - 87s - loss: 0.4033 - accuracy: 0.8765\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dd602253c453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e496d4151a1c>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model ... '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_epochs_to_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e496d4151a1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(p_model, p_training_image_data, p_trainging_labels, p_batch_size, p_epochs_to_train, p_verbose_level)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_epochs_to_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_verbose_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/myProjectDir/myProjectEnv/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
